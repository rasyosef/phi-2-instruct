{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-KK_n2rhxkY"
      },
      "outputs": [],
      "source": [
        "! nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -U --quiet datasets evaluate torch transformers accelerate trl peft"
      ],
      "metadata": {
        "id": "UifAR_OsiSI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Load Dataset**"
      ],
      "metadata": {
        "id": "um5L0wq7iVIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "combined_dpo = load_dataset(\"rasyosef/ultrafeedback-orca-math-dpo\")\n",
        "combined_dpo"
      ],
      "metadata": {
        "id": "aEah_ZjSiSyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(3):\n",
        "  print(combined_dpo[\"train\"][i][\"prompt\"])\n",
        "  print(combined_dpo[\"train\"][i][\"chosen\"])\n",
        "  print(combined_dpo[\"train\"][i][\"rejected\"])\n",
        "  print(\"\\n\\n\")"
      ],
      "metadata": {
        "id": "lIWa_geFicOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Load Model**"
      ],
      "metadata": {
        "id": "E1XZGKSkid-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "model_id = \"rasyosef/phi-2-sft-openhermes-128k-v2-merged\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"cuda\",\n",
        "    # attn_implementation=\"flash_attention_2\"\n",
        "  )"
      ],
      "metadata": {
        "id": "6qOKuoVUidL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"left\"\n",
        "print(model)"
      ],
      "metadata": {
        "id": "MneaXHWLik6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [{\"role\":\"user\", \"content\":\"Who was the last king of Germany?\"}]\n",
        "\n",
        "def chat(messages, max_new_tokens=8):\n",
        "  tokenized_messages = tokenizer.apply_chat_template(messages, return_tensors=\"pt\", add_generation_prompt=True).to(\"cuda\")\n",
        "  outputs = model.generate(tokenized_messages, max_new_tokens=max_new_tokens)\n",
        "  print(tokenizer.decode(outputs[0]))\n",
        "\n",
        "chat(messages, max_new_tokens=128)"
      ],
      "metadata": {
        "id": "bCJWiFNwinCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Inspect Dataset**"
      ],
      "metadata": {
        "id": "vK6GPUg0io9Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lengths Distribution\n",
        "prompt_lengths = sorted(combined_dpo[\"train\"][\"prompt_length\"])\n",
        "chosen_lengths = sorted(combined_dpo[\"train\"][\"chosen_length\"])\n",
        "rejected_lengths = sorted(combined_dpo[\"train\"][\"rejected_length\"])\n",
        "\n",
        "print(\"prompt_lengths:\", prompt_lengths[1024], prompt_lengths[4096], prompt_lengths[8000], prompt_lengths[12000], max(prompt_lengths))\n",
        "print(\"chosen_lengths:\", chosen_lengths[1024], chosen_lengths[4096], chosen_lengths[8000], chosen_lengths[12000], max(chosen_lengths))\n",
        "print(\"rejected_lengths:\", rejected_lengths[1024], rejected_lengths[4096], rejected_lengths[8000], rejected_lengths[12000], max(rejected_lengths))"
      ],
      "metadata": {
        "id": "4TKXAL5hisST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 448\n",
        "combined_dpo_filtered = combined_dpo.filter(lambda example: example['prompt_length'] + example['chosen_length'] < MAX_LENGTH and example['prompt_length'] + example['rejected_length'] < MAX_LENGTH)\n",
        "combined_dpo_filtered"
      ],
      "metadata": {
        "id": "ulvrQu_4iuJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "Counter(combined_dpo_filtered[\"train\"][\"source_dataset\"]), Counter(combined_dpo_filtered[\"test\"][\"source_dataset\"])"
      ],
      "metadata": {
        "id": "E1JHXPv8iwZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random.seed(42)\n",
        "\n",
        "combined_dpo_final = combined_dpo_filtered.filter(\n",
        "    lambda row: row['source_dataset'] != \"ultrafeedback\" or (row['source_dataset'] == \"ultrafeedback\" and random.random()<=0.67)\n",
        ")\n",
        "#combined_dpo_final = combined_dpo_final.filter(lambda row: \"translat\" not in (row[\"prompt\"]+row[\"chosen\"]).lower())\n",
        "combined_dpo_final"
      ],
      "metadata": {
        "id": "9CZOJUrkizWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "Counter(combined_dpo_final[\"train\"][\"source_dataset\"]), Counter(combined_dpo_final[\"test\"][\"source_dataset\"])"
      ],
      "metadata": {
        "id": "rk1ZIV8ei1V0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = combined_dpo_final[\"train\"].shuffle().select(range(5))\n",
        "\n",
        "for row in sample:\n",
        "  print(row[\"source_dataset\"])\n",
        "  print(row[\"prompt\"])\n",
        "  print(row[\"chosen\"])\n",
        "  print(row[\"rejected\"])\n",
        "  print(\"\\n-----------------------------------------------------\\n\")"
      ],
      "metadata": {
        "id": "_oP_QlJFi3VX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **DPO with TRL**"
      ],
      "metadata": {
        "id": "uOp5uVoTi4Nr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig, get_peft_model, cast_mixed_precision_params\n",
        "\n",
        "peft_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    # Target all linear layers\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"dense\", \"fc1\", \"fc2\", \"lm_head\"]\n",
        ")\n",
        "\n",
        "dpo_model = get_peft_model(model, peft_config)\n",
        "cast_mixed_precision_params(dpo_model, dtype=torch.float16)\n",
        "dpo_model.print_trainable_parameters()"
      ],
      "metadata": {
        "id": "1ZlzDf3Ki64o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from trl import DPOConfig, DPOTrainer\n",
        "\n",
        "batch_size = 4 # On T4 or P100, set batch_size to 1 to avoid Cuda OOM\n",
        "gradient_accum_steps = 4\n",
        "epochs = 2\n",
        "\n",
        "new_model_id = \"phi-2-dpo\"\n",
        "\n",
        "eval_steps = 100 #len(combined_dpo_final[\"train\"]) // (batch_size * gradient_accum_steps * 8)\n",
        "save_steps = eval_steps * 2\n",
        "logging_steps=eval_steps\n",
        "\n",
        "print(\"Eval Steps:\", eval_steps)\n",
        "print(\"Save Steps:\", save_steps)\n",
        "\n",
        "dpo_config = DPOConfig(\n",
        "  output_dir=new_model_id,\n",
        "  beta=0.1,\n",
        "  max_length=512,\n",
        "  max_prompt_length=512,\n",
        "  per_device_train_batch_size=batch_size,\n",
        "  per_device_eval_batch_size=batch_size,\n",
        "  gradient_accumulation_steps=gradient_accum_steps,\n",
        "  num_train_epochs=epochs,\n",
        "  learning_rate=2e-6,\n",
        "  warmup_steps=250,\n",
        "  lr_scheduler_type=\"cosine\",\n",
        "  remove_unused_columns=False,\n",
        "  fp16=True,\n",
        "  logging_strategy=\"steps\",\n",
        "  logging_steps=logging_steps,\n",
        "  eval_strategy=\"steps\",\n",
        "  eval_steps=eval_steps,\n",
        "  save_strategy=\"steps\",\n",
        "  save_steps=save_steps,\n",
        "  seed=42,\n",
        "  # push_to_hub=True,\n",
        "  # hub_token=userdata.get(\"HF_TOKEN\"),\n",
        "\n",
        "  # gradient_checkpointing=True,\n",
        ")"
      ],
      "metadata": {
        "id": "OLxAiOwii-0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = DPOTrainer(\n",
        "    dpo_model, # left ref_model null\n",
        "    args=dpo_config,\n",
        "    train_dataset=combined_dpo_final[\"train\"],\n",
        "    eval_dataset=combined_dpo_final[\"test\"],\n",
        "    tokenizer=tokenizer\n",
        ")"
      ],
      "metadata": {
        "id": "xpRVAbPZjCGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "qvcZA0sTjDL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\":\"system\", \"content\": \"You are an AI assistant that follows instruction extremely well. Help as much as you can.\"},\n",
        "    {\"role\":\"user\", \"content\":\"What is J. Robert Oppenheimer known for?\"}\n",
        "]\n",
        "\n",
        "def chat(model, messages, max_new_tokens=8):\n",
        "  tokenized_messages = tokenizer.apply_chat_template(messages, return_tensors=\"pt\", add_generation_prompt=True).to(\"cuda\")\n",
        "  outputs = model.generate(tokenized_messages, max_new_tokens=max_new_tokens)\n",
        "  print(tokenizer.decode(outputs[0]))\n",
        "\n",
        "chat(dpo_model, messages, max_new_tokens=256)"
      ],
      "metadata": {
        "id": "kGX2gE8IjGTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\":\"system\", \"content\": \"You are an AI assistant that follows instruction extremely well. Help as much as you can.\"},\n",
        "    {\"role\":\"user\", \"content\":\"Who was the last king of Germany?\"}\n",
        "]\n",
        "\n",
        "chat(dpo_model, messages, max_new_tokens=256)"
      ],
      "metadata": {
        "id": "eRto2b0ujKS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Push trainer to Hub\n",
        "trainer.push_to_hub()"
      ],
      "metadata": {
        "id": "4JvLKwMwjLYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(model), type(dpo_model)"
      ],
      "metadata": {
        "id": "6gxC4LQDjW4B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}